{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Tutorial (MNIST Dataset)\n",
    "\n",
    "* Usually used as the last layer in an NN for classification.\n",
    "* Activation function a_i = exp(z_i)/sum(all(exp(z)).\n",
    "* The exponentials ensure that all the output activations are positive. And the sum in the denominator ensures that the softmax outputs sum to 1.\n",
    "* Can think of softmax as a way of rescaling the z_i, and then squishing them together to form a probability distribution.\n",
    "\n",
    "* Tutorials:\n",
    "    * http://neuralnetworksanddeeplearning.com/chap3.html#softmax\n",
    "    * https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n",
    "    * http://colah.github.io/posts/2014-10-Visualizing-MNIST/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input is 28x28 image matrix denoted as a vector of 784 dimensions (with values from 0 to 1 indicating gray values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])  # None means that dim can be of any length (i.e total number of images in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the variables for the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10])) # 10 classes:- digits 0 to 9\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax function and layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = tf.matmul(x, W) + b # activation function, gives the evidence supporting the claim for a class or against it\n",
    "y = tf.nn.softmax(evidence)  # softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis) # here logits = tf.matmul(x,W) + b, axis = -1 (last dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10]) # The true output required (10 classes, n images)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) # cross entropy cost function\n",
    "## ----- tf.reduce_mean computes the mean over all the examples in the batch\n",
    "## ----- tf.reduce_sum adds the elements in the second dimension of y, due to the reduction_indices=[1] parameter\n",
    "\n",
    "\n",
    "# cross_entropy_2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=evidence, labels=y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: tf.nn.softmax_cross_entropy_with_logits_v2(evidence) can be used to combine the above softmax function and cross-entropy cost. This is more stable numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train by performing backprogation using gradient descent to minimise error, update parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) # learning rate 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "#### Each step of the loop, we get a \"batch\" of one hundred random data points from our training set. We run train_step feeding in the batches data to replace the placeholders.\n",
    "\n",
    "#### Using small batches of random data is called stochastic training -- in this case, stochastic gradient descent. Ideally, we'd like to use all our data for every step of training because that would give us a better sense of what we should be doing, but that's expensive. So, instead, we use a different subset every time. Doing this is cheap and has much of the same benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100) # batch_ys: one hot vectors\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1)) # tf.argmax gives index of highest value in a tensor along an axis\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # [True, False, True, True] would become [1,0,1,1] which would become 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9188\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})) # Test accuracy on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [9] Actual: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f78db129350>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78d10dd7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "idx = 20 # change value to test different image\n",
    "pred = sess.run(tf.argmax(y,1), feed_dict={x: np.expand_dims(mnist.test.images[idx,:],0)})\n",
    "print \"Prediction:\", pred, \"Actual:\",np.argmax(mnist.test.labels[idx,:],-1)#tf.argmax(np.expand_dims(mnist.test.labels[1],0))#\n",
    "\n",
    "plt.imshow(np.reshape(mnist.test.images[idx,:],(28,28)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
