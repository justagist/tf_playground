{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Tutorial (MNIST Dataset)\n",
    "\n",
    "* Usually used as the last layer in an NN for classification.\n",
    "* Activation function a_i = exp(z_i)/sum(all(exp(z)).\n",
    "* The exponentials ensure that all the output activations are positive. And the sum in the denominator ensures that the softmax outputs sum to 1.\n",
    "* Can think of softmax as a way of rescaling the z_i, and then squishing them together to form a probability distribution.\n",
    "\n",
    "* Tutorials:\n",
    "    * http://neuralnetworksanddeeplearning.com/chap3.html#softmax\n",
    "    * https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n",
    "    * http://colah.github.io/posts/2014-10-Visualizing-MNIST/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input is 28x28 image matrix denoted as a vector of 784 dimensions (with values from 0 to 1 indicating gray values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])  # None means that dim can be of any length (i.e total number of images in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the variables for the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10])) # 10 classes:- digits 0 to 9\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax function and layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = tf.matmul(x, W) + b # activation function, gives the evidence supporting the claim for a class or against it\n",
    "y = tf.nn.softmax(evidence)  # softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis) # here logits = tf.matmul(x,W) + b, axis = -1 (last dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10]) # The true output required (10 classes, n images)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) # cross entropy cost function\n",
    "# tf.reduce_mean computes the mean over all the examples in the batch\n",
    "# tf.reduce_sum adds the elements in the second dimension of y, due to the reduction_indices=[1] parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: tf.nn.softmax_cross_entropy_with_logits_v2(evidence) can be used to combine the above softmax function and cross-entropy cost. This is more stable numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train by performing backprogation using gradient descent to minimise error, update parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) # learning rate 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "#### Each step of the loop, we get a \"batch\" of one hundred random data points from our training set. We run train_step feeding in the batches data to replace the placeholders.\n",
    "\n",
    "#### Using small batches of random data is called stochastic training -- in this case, stochastic gradient descent. Ideally, we'd like to use all our data for every step of training because that would give us a better sense of what we should be doing, but that's expensive. So, instead, we use a different subset every time. Doing this is cheap and has much of the same benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100) # batch_ys: one hot vectors\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1)) # tf.argmax gives index of highest value in a tensor along an axis\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # [True, False, True, True] would become [1,0,1,1] which would become 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})) # Test accuracy on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [4] Actual: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f78d11895d0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78d325ab10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "idx = 20 # change value to test different image\n",
    "pred = sess.run(tf.argmax(y,1), feed_dict={x: np.expand_dims(mnist.test.images[idx,:],0)})\n",
    "print \"Prediction:\", pred, \"Actual:\",np.argmax(mnist.test.labels[idx,:],-1)#tf.argmax(np.expand_dims(mnist.test.labels[1],0))#\n",
    "\n",
    "plt.imshow(np.reshape(mnist.test.images[idx,:],(28,28)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
